{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12d0006a-942c-4274-a2c8-7ebe0c384016",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fa06bfb-667d-4afc-b871-d28ce4603ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea79b27-6338-48f6-a8f1-05cc8ce91550",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=[]\n",
    "for i in range(1, 50000 + 1):\n",
    "    image_path = os.path.join('train', f\"{i}.png\")\n",
    "    train.append(image_path)\n",
    "\n",
    "\n",
    "#print(train[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2ff185c-7af3-401e-b6ba-39f0ce20053c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id       label  numeric_labels\n",
      "0   1        frog               0\n",
      "1   2       truck               1\n",
      "2   3       truck               1\n",
      "3   4        deer               2\n",
      "4   5  automobile               3\n",
      "tensor([0, 1, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file containing labels\n",
    "labels = pd.read_csv(\"trainLabels.csv\")\n",
    "\n",
    "# Convert labels to numeric values\n",
    "labels['numeric_labels'] = pd.factorize(labels['label'])[0]\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(labels.head())\n",
    "\n",
    "main_labels=torch.tensor(labels['numeric_labels'])\n",
    "\n",
    "print(main_labels[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76202195-c24e-4ebc-aff7-0cfa1b2a840b",
   "metadata": {},
   "source": [
    "## convulational layer build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ddbb3d18-f70b-433d-a881-fd9c1227d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv:\n",
    "    def __init__(self,num_filters):\n",
    "        self.num_filters=num_filters\n",
    "        self.filters = torch.randn(num_filters, 5, 5) /25\n",
    "        \n",
    "\n",
    "    def iterate(self,image):\n",
    "        h,w=image.shape\n",
    "        \n",
    "        for i in range(h-4):  #-4 since we take 5X5x8 as conv kernal.\n",
    "            for j in range(w-4):\n",
    "                region=image[i:i+5,j:j+5]\n",
    "                region=torch.tensor(region)\n",
    "            yield region,i,j\n",
    "\n",
    "    def forward(self,inp):\n",
    "        h,w=inp.shape\n",
    "        out=torch.zeros((h-4,w-4,self.num_filters))\n",
    "\n",
    "        for region,i,j in self.iterate(inp):\n",
    "            out[i,j]=torch.sum(region * self.filters,axis=(1,2))\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642e3745-ac47-416d-a1a2-75d7ba12c8a2",
   "metadata": {},
   "source": [
    "## maxpool build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3384edba-81ab-414b-a067-71b262c1b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Maxpool:\n",
    "    def iterate(self,image):\n",
    "        h,w,num_filters=image.shape\n",
    "\n",
    "        new_h = h//2\n",
    "        new_w = w//2\n",
    "\n",
    "        for i in range(new_h):\n",
    "            for j in range(new_w):\n",
    "                region = image[(i * 2):(i * 2 + 2), (j * 2):(j * 2 + 2)]   #stride=2 \n",
    "            yield region,i,j\n",
    "\n",
    "    def forward(self,inp):\n",
    "        h,w,num_filters = inp.shape\n",
    "        out=torch.zeros((h//2,w//2,num_filters))\n",
    "\n",
    "        for region,i,j in self.iterate(inp):\n",
    "            out[i,j]=torch.amax(region,axis=(0,1))  \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3ae205-6642-4cfa-8f28-09cd86649419",
   "metadata": {},
   "source": [
    "## softmaxing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6b7062d7-6404-4d3f-94c3-02a807bb88c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self,input_len,neurons):\n",
    "        self.weights= torch.randn(input_len,neurons)/input_len\n",
    "        self.bias=torch.zeros(neurons)\n",
    "        \n",
    "    def forward(self,inp):\n",
    "        inp=inp.flatten()\n",
    "        \n",
    "        \n",
    "        input_len,neurons = self.weights.shape\n",
    "\n",
    "        outs=torch.matmul(inp,self.weights)+self.bias\n",
    "\n",
    "        exp=torch.exp(outs)\n",
    "\n",
    "        return exp/torch.sum(exp,axis=0)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c1851dd7-9b59-4443-8299-66856670f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_1=Conv(8)\n",
    "mp=Maxpool()\n",
    "sf=Softmax(14*14*8,10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "886aa8b1-7aa2-4c11-ab75-1d8863c77895",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters=[conv_1.filters,sf.weights,sf.bias]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5e5944c1-0be8-4301-a5bb-a55f11012ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im-> tensor([[ 61,  44,  48,  ..., 137, 130, 128],\n",
      "        [ 18,   0,  10,  ...,  94,  89,  94],\n",
      "        [ 23,   8,  31,  ...,  90,  90,  80],\n",
      "        ...,\n",
      "        [172, 153, 156,  ..., 133,  35,  38],\n",
      "        [146, 128, 143,  ..., 152,  69,  59],\n",
      "        [150, 136, 146,  ..., 188, 123,  98]], dtype=torch.uint8)\n",
      "after conv-> tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<CopySlices>)\n",
      "after mp-> tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<CopySlices>)\n",
      "logits-> tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([[ 61,  44,  48,  ..., 137, 130, 128],\n",
      "        [ 18,   0,  10,  ...,  94,  89,  94],\n",
      "        [ 23,   8,  31,  ...,  90,  90,  80],\n",
      "        ...,\n",
      "        [172, 153, 156,  ..., 133,  35,  38],\n",
      "        [146, 128, 143,  ..., 152,  69,  59],\n",
      "        [150, 136, 146,  ..., 188, 123,  98]], dtype=torch.uint8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshay\\AppData\\Local\\Temp\\ipykernel_5636\\491017553.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  region=torch.tensor(region)\n"
     ]
    }
   ],
   "source": [
    "epoch=10\n",
    "for _ in range(1):\n",
    "    for i in range(1):\n",
    "        im=torch.tensor(cv2.imread(train[i], cv2.IMREAD_GRAYSCALE))\n",
    "        print(\"im->\",im)\n",
    "        out=conv_1.forward(im)\n",
    "        print(\"after conv->\",out)\n",
    "        out=mp.forward(out)\n",
    "        print(\"after mp->\",out)\n",
    "        logits=sf.forward(out)\n",
    "        print(\"logits->\",logits)\n",
    "        \n",
    "\n",
    "        loss=F.cross_entropy(logits,main_labels[i])\n",
    "\n",
    "        for p in parameters:\n",
    "            p.grad=None\n",
    "        loss.backward()\n",
    "\n",
    "        lr=0.01\n",
    "        for p in parameters:\n",
    "            p.data-=lr*p.grad\n",
    "    #print(loss.item())\n",
    "print(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73dfa7f-8b6e-4430-9db6-5ef634d886bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
